{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3782165/1053928295.py:216: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  OG_train_df = pd.read_csv(TRAIN_CSV)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Num malignant: 81\n",
      "Validation - Num benign: 80133\n",
      "Training - Num malignant: 42381\n",
      "Training - Num benign: 329653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3782165/1053928295.py:248: DtypeWarning: Columns (4,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.fulldata = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Training set size: 84762\n",
      "Validation set size: 80214\n",
      "EPOCH: 1\n",
      "Epoch [1/20] Train Loss: 0.4686 Val Loss: 0.3069\n",
      "Val TN: 71385 FN: 48 \n",
      "TP: 33 FP: 8748\n",
      "Val Accuracy: 0.8903\n",
      "AUC: 0.7553\n",
      "pAUC: 0.0719\n",
      "f1 score: 0.0074\n",
      "\n",
      "Training set size: 84762\n",
      "Validation set size: 80214\n",
      "EPOCH: 2\n",
      "Epoch [2/20] Train Loss: 0.3148 Val Loss: 0.2397\n",
      "Val TN: 73710 FN: 48 \n",
      "TP: 33 FP: 6423\n",
      "Val Accuracy: 0.9193\n",
      "AUC: 0.7737\n",
      "pAUC: 0.0769\n",
      "f1 score: 0.0101\n",
      "\n",
      "Training set size: 84762\n",
      "Validation set size: 80214\n",
      "EPOCH: 3\n",
      "Epoch [3/20] Train Loss: 0.2850 Val Loss: 0.2357\n",
      "Val TN: 73639 FN: 46 \n",
      "TP: 35 FP: 6494\n",
      "Val Accuracy: 0.9185\n",
      "AUC: 0.7886\n",
      "pAUC: 0.0802\n",
      "f1 score: 0.0106\n",
      "\n",
      "Training set size: 84762\n",
      "Validation set size: 80214\n",
      "EPOCH: 4\n",
      "Epoch [4/20] Train Loss: 0.2732 Val Loss: 0.2021\n",
      "Val TN: 74858 FN: 48 \n",
      "TP: 33 FP: 5275\n",
      "Val Accuracy: 0.9336\n",
      "AUC: 0.7916\n",
      "pAUC: 0.0807\n",
      "f1 score: 0.0122\n",
      "\n",
      "Training set size: 84762\n",
      "Validation set size: 80214\n",
      "EPOCH: 5\n",
      "Epoch [5/20] Train Loss: 0.2627 Val Loss: 0.2053\n",
      "Val TN: 74595 FN: 46 \n",
      "TP: 35 FP: 5538\n",
      "Val Accuracy: 0.9304\n",
      "AUC: 0.7981\n",
      "pAUC: 0.0845\n",
      "f1 score: 0.0124\n",
      "\n",
      "Training set size: 84762\n",
      "Validation set size: 80214\n",
      "EPOCH: 6\n",
      "Epoch [6/20] Train Loss: 0.2574 Val Loss: 0.1834\n",
      "Val TN: 75372 FN: 49 \n",
      "TP: 32 FP: 4761\n",
      "Val Accuracy: 0.9400\n",
      "AUC: 0.7989\n",
      "pAUC: 0.0830\n",
      "f1 score: 0.0131\n",
      "\n",
      "Training set size: 84762\n",
      "Validation set size: 80214\n",
      "EPOCH: 7\n",
      "Epoch [7/20] Train Loss: 0.2536 Val Loss: 0.1983\n",
      "Val TN: 74836 FN: 47 \n",
      "TP: 34 FP: 5297\n",
      "Val Accuracy: 0.9334\n",
      "AUC: 0.8060\n",
      "pAUC: 0.0841\n",
      "f1 score: 0.0126\n",
      "\n",
      "Training set size: 84762\n",
      "Validation set size: 80214\n",
      "EPOCH: 8\n",
      "Epoch [8/20] Train Loss: 0.2505 Val Loss: 0.1556\n",
      "Val TN: 76303 FN: 46 \n",
      "TP: 35 FP: 3830\n",
      "Val Accuracy: 0.9517\n",
      "AUC: 0.8088\n",
      "pAUC: 0.0918\n",
      "f1 score: 0.0177\n",
      "\n",
      "Training set size: 84762\n",
      "Validation set size: 80214\n",
      "EPOCH: 9\n",
      "Epoch [9/20] Train Loss: 0.2473 Val Loss: 0.1920\n",
      "Val TN: 74884 FN: 45 \n",
      "TP: 36 FP: 5249\n",
      "Val Accuracy: 0.9340\n",
      "AUC: 0.8118\n",
      "pAUC: 0.0910\n",
      "f1 score: 0.0134\n",
      "\n",
      "Training set size: 84762\n",
      "Validation set size: 80214\n",
      "EPOCH: 10\n",
      "Epoch [11/20] Train Loss: 0.2392 Val Loss: 0.1683\n",
      "Val TN: 75783 FN: 48 \n",
      "TP: 33 FP: 4350\n",
      "Val Accuracy: 0.9452\n",
      "AUC: 0.8112\n",
      "pAUC: 0.0903\n",
      "f1 score: 0.0148\n",
      "\n",
      "Training set size: 84762\n",
      "Validation set size: 80214\n",
      "EPOCH: 12\n",
      "Epoch [12/20] Train Loss: 0.2403 Val Loss: 0.1651\n",
      "Val TN: 75870 FN: 48 \n",
      "TP: 33 FP: 4263\n",
      "Val Accuracy: 0.9463\n",
      "AUC: 0.8127\n",
      "pAUC: 0.0895\n",
      "f1 score: 0.0151\n",
      "\n",
      "Training set size: 84762\n",
      "Validation set size: 80214\n",
      "EPOCH: 13\n",
      "Epoch [13/20] Train Loss: 0.2370 Val Loss: 0.1619\n",
      "Val TN: 75964 FN: 48 \n",
      "TP: 33 FP: 4169\n",
      "Val Accuracy: 0.9474\n",
      "AUC: 0.8131\n",
      "pAUC: 0.0922\n",
      "f1 score: 0.0154\n",
      "\n",
      "Training set size: 84762\n",
      "Validation set size: 80214\n",
      "EPOCH: 14\n",
      "Epoch [14/20] Train Loss: 0.2374 Val Loss: 0.1772\n",
      "Val TN: 75377 FN: 47 \n",
      "TP: 34 FP: 4756\n",
      "Val Accuracy: 0.9401\n",
      "AUC: 0.8142\n",
      "pAUC: 0.0915\n",
      "f1 score: 0.0140\n",
      "\n",
      "Training set size: 84762\n",
      "Validation set size: 80214\n",
      "EPOCH: 15\n",
      "Epoch [15/20] Train Loss: 0.2348 Val Loss: 0.1550\n",
      "Val TN: 76137 FN: 48 \n",
      "TP: 33 FP: 3996\n",
      "Val Accuracy: 0.9496\n",
      "AUC: 0.8163\n",
      "pAUC: 0.0930\n",
      "f1 score: 0.0161\n",
      "\n",
      "Training set size: 84762\n",
      "Validation set size: 80214\n",
      "EPOCH: 16\n",
      "Epoch [16/20] Train Loss: 0.2338 Val Loss: 0.1689\n",
      "Val TN: 75639 FN: 47 \n",
      "TP: 34 FP: 4494\n",
      "Val Accuracy: 0.9434\n",
      "AUC: 0.8053\n",
      "pAUC: 0.0858\n",
      "f1 score: 0.0148\n",
      "\n",
      "Training set size: 84762\n",
      "Validation set size: 80214\n",
      "EPOCH: 17\n",
      "Epoch [17/20] Train Loss: 0.2322 Val Loss: 0.1791\n",
      "Val TN: 75255 FN: 46 \n",
      "TP: 35 FP: 4878\n",
      "Val Accuracy: 0.9386\n",
      "AUC: 0.8098\n",
      "pAUC: 0.0869\n",
      "f1 score: 0.0140\n",
      "\n",
      "Training set size: 84762\n",
      "Validation set size: 80214\n",
      "EPOCH: 18\n",
      "Epoch [18/20] Train Loss: 0.2333 Val Loss: 0.1627\n",
      "Val TN: 75817 FN: 48 \n",
      "TP: 33 FP: 4316\n",
      "Val Accuracy: 0.9456\n",
      "AUC: 0.8168\n",
      "pAUC: 0.0944\n",
      "f1 score: 0.0149\n",
      "\n",
      "Training set size: 84762\n",
      "Validation set size: 80214\n",
      "EPOCH: 19\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import torchvision\n",
    "import timm\n",
    "\n",
    "\n",
    "# params\n",
    "FREEZE = True # whether or not to freeze the weights\n",
    "EPOCHS = 20 # number of training epochs\n",
    "DUPE = True\n",
    "DUPE_COUNT = 8 \n",
    "#TRAIN_DIR = 'C:\\\\Users\\\\rngki\\\\Downloads\\\\train_images_hair_removed_dullrazor\\\\'\n",
    "TRAIN_CSV = './og_train_dataset_with_labeled_cancer_and_skin_tone.csv'\n",
    "TRAIN_DIR = ['./ISIC_2024_Training_Input/ISIC_2024_Training_Input/'] #,\"C:\\\\Users\\\\rngki\\\\Downloads\\\\train_images_hair_removed_dullrazor\\\\\"]\n",
    "AUG_DIR = './cleaned_styled_data/cleaned_styled_data/' #FIX\n",
    "AUG_CSV = './cleaned_augmented_data_with_labeled_cancer.csv' #FIX\n",
    "#TRAIN_CSV = 'C:\\\\Users\\\\rngki\\\\Downloads\\\\train-metadata.csv'\n",
    "#TRAIN_CSV = 'C:\\\\Users\\\\rngki\\\\Downloads\\\\cleaned_styled_data\\\\cleaned_styled_data\\\\cleaned_augmented_data.csv'\n",
    "#TEST_DIR = 'C:\\\\Users\\\\rngki\\\\Downloads\\\\test_images_hair_removed_dullrazor\\\\'\n",
    "#TEST_CSV = 'C:\\\\Users\\\\rngki\\\\Downloads\\\\test_dataset_with_skin_tone.csv'\n",
    "\n",
    "MODELS = [\"coatnet\",\"efficientnet\", \"resnet50\", \"resnet34\"]\n",
    "\n",
    "DATA_NAMES = ['ISIC_2024_Training_Input_mixed_styled']\n",
    "TEST_DIR = ['./ISIC_2024_Training_Input/ISIC_2024_Training_Input/']\n",
    "TEST_CSV = './og_test_dataset_with_labeled_cancer_and_skin_tone.csv'\n",
    "\n",
    "\"\"\"\n",
    "2024 ISIC Challenge primary prize scoring metric\n",
    "\n",
    "Given a list of binary labels, an associated list of prediction \n",
    "scores ranging from [0,1], this function produces, as a single value, \n",
    "the partial area under the receiver operating characteristic (pAUC) \n",
    "above a given true positive rate (TPR).\n",
    "https://en.wikipedia.org/wiki/Partial_Area_Under_the_ROC_Curve.\n",
    "\n",
    "(c) 2024 Nicholas R Kurtansky, MSKCC\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "def initialize_model(model_name, num_classes=1):\n",
    "    model = None\n",
    "    \n",
    "    if model_name == \"efficientnet\":\n",
    "        model = torchvision.models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        num_ftrs = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "        final_layer = model.classifier[1]\n",
    "    \n",
    "    elif model_name == \"resnet34\":\n",
    "        model = torchvision.models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        final_layer = model.fc\n",
    "    \n",
    "    elif model_name == \"resnet50\":\n",
    "        model = torchvision.models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        final_layer = model.fc\n",
    "    \n",
    "    elif model_name == \"coatnet\":\n",
    "        model = timm.create_model('coatnet_0_rw_224', pretrained=True)\n",
    "        num_ftrs = model.head.fc.in_features\n",
    "        model.head.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        final_layer = model.head.fc\n",
    "    \n",
    "    elif model_name == \"deit\":\n",
    "        model = timm.create_model('deit_base_patch16_224', pretrained=True)\n",
    "        num_ftrs = model.head.in_features\n",
    "        model.head = nn.Linear(num_ftrs, num_classes)\n",
    "        final_layer = model.head\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name\")\n",
    "    \n",
    "    # Freeze all layers\n",
    "    if FREEZE:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Unfreeze only the final classification layer\n",
    "        for param in final_layer.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    return model.to(device)\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, min_tpr: float=0.80) -> float:\n",
    "    '''\n",
    "    2024 ISIC Challenge metric: pAUC\n",
    "    \n",
    "    Given a solution file and submission file, this function returns the\n",
    "    the partial area under the receiver operating characteristic (pAUC) \n",
    "    above a given true positive rate (TPR) = 0.80.\n",
    "    https://en.wikipedia.org/wiki/Partial_Area_Under_the_ROC_Curve.\n",
    "    \n",
    "    (c) 2024 Nicholas R Kurtansky, MSKCC\n",
    "\n",
    "    Args:\n",
    "        solution: ground truth pd.DataFrame of 1s and 0s\n",
    "        submission: solution dataframe of predictions of scores ranging [0, 1]\n",
    "\n",
    "    Returns:\n",
    "        Float value range [0, max_fpr]\n",
    "    '''\n",
    "    for col in solution.columns:\n",
    "        if col != 'is_malignant':\n",
    "            del solution[col]\n",
    "    \n",
    "    for col in submission.columns:\n",
    "        if col != 'prediction':\n",
    "            del submission[col]\n",
    "\n",
    "    # check submission is numeric\n",
    "    if not pandas.api.types.is_numeric_dtype(submission.values):\n",
    "        raise ParticipantVisibleError('Submission target column must be numeric')\n",
    "\n",
    "    # rescale the target. set 0s to 1s and 1s to 0s (since sklearn only has max_fpr)\n",
    "    v_gt = abs(solution.values.ravel()-1)\n",
    "    \n",
    "    # flip the submissions to their compliments\n",
    "    v_pred = -1.0*submission.values.ravel()\n",
    "\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "\n",
    "    # using sklearn.metric functions: (1) roc_curve and (2) auc\n",
    "    fpr, tpr, _ = roc_curve(v_gt, v_pred, sample_weight=None)\n",
    "    if max_fpr is None or max_fpr == 1:\n",
    "        return auc(fpr, tpr)\n",
    "    if max_fpr <= 0 or max_fpr > 1:\n",
    "        raise ValueError(\"Expected min_tpr in range [0, 1), got: %r\" % min_tpr)\n",
    "        \n",
    "    # Add a single point at max_fpr by linear interpolation\n",
    "    stop = np.searchsorted(fpr, max_fpr, \"right\")\n",
    "    x_interp = [fpr[stop - 1], fpr[stop]]\n",
    "    y_interp = [tpr[stop - 1], tpr[stop]]\n",
    "    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n",
    "    fpr = np.append(fpr[:stop], max_fpr)\n",
    "    partial_auc = auc(fpr, tpr)\n",
    "\n",
    "#     # Equivalent code that uses sklearn's roc_auc_score\n",
    "#     v_gt = abs(np.asarray(solution.values)-1)\n",
    "#     v_pred = np.array([1.0 - x for x in submission.values])\n",
    "#     max_fpr = abs(1-min_tpr)\n",
    "#     partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "#     # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n",
    "#     # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n",
    "#     partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    \n",
    "    return(partial_auc)\n",
    "\n",
    "for dir in range(len(TRAIN_DIR)):\n",
    "    AUG = True\n",
    "    USE_SPLIT = False\n",
    "\n",
    "    MALIGNANT = 'target'\n",
    "    # MALIGNANT = 'target'\n",
    "    MALIG_IDX = 1\n",
    "    # MALIG_IDX = 3\n",
    "\n",
    "    if not TEST_DIR:\n",
    "        TEST_DIR = TRAIN_DIR[dir]\n",
    "        USE_SPLIT = True\n",
    "    if not TEST_CSV:\n",
    "        TEST_CSV = TRAIN_CSV\n",
    "        USE_SPLIT = True\n",
    "\n",
    "    # def balance_classes(df, label_col=MALIGNANT):\n",
    "    #     # Separate malignant and non-malignant samples\n",
    "    #     malig_df = df[df[label_col] == 1]\n",
    "    #     non_malig_df = df[df[label_col] == 0]\n",
    "\n",
    "    #     # Get the minority count\n",
    "    #     min_count = min(len(malig_df), len(non_malig_df))\n",
    "\n",
    "    #     # Downsample both classes to min_count (or oversample malignant if needed)\n",
    "    #     non_malig_df_balanced = non_malig_df.sample(n=min_count, random_state=42)\n",
    "    #     malig_df_balanced = malig_df.sample(n=min_count, replace=True, random_state=42)  # oversample if needed\n",
    "\n",
    "    #     # Concatenate back\n",
    "    #     balanced_df = pd.concat([malig_df_balanced, non_malig_df_balanced]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    #     return balanced_df\n",
    "\n",
    "    if USE_SPLIT:\n",
    "        df = pd.read_csv(TRAIN_CSV)\n",
    "        #df = pd.read_csv('C:\\\\Users\\\\rngki\\\\Downloads\\\\cleaned_styled_data\\\\cleaned_styled_data\\\\cleaned_augmented_data.csv')\n",
    "        print(f\"num malignant: {sum(df[MALIGNANT])}\")\n",
    "\n",
    "        # downsample for time\n",
    "        df = df.sample(frac=.1, random_state=42)\n",
    "\n",
    "        train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[MALIGNANT], random_state=42)\n",
    "    elif AUG:\n",
    "        OG_train_df = pd.read_csv(TRAIN_CSV)\n",
    "        AUG_train = pd.read_csv(AUG_CSV)\n",
    "        # Add a source column to each\n",
    "        OG_train_df[\"source\"] = 0\n",
    "        AUG_train[\"source\"] = 1\n",
    "        \n",
    "        #SOURCE_IDX = AUG_train.columns.get_loc(\"source\")\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "        train_df = pd.concat([OG_train_df, AUG_train], ignore_index=True)\n",
    "        val_df = pd.read_csv(TEST_CSV)\n",
    "    else:\n",
    "        train_df = pd.read_csv(TRAIN_CSV)\n",
    "        val_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "    if DUPE:\n",
    "        malig_df = train_df[train_df[MALIGNANT] == 1]\n",
    "        malig_df = pd.concat([malig_df]*DUPE_COUNT, ignore_index=True)\n",
    "\n",
    "        train_df = pd.concat([train_df, malig_df], ignore_index=True)\n",
    "\n",
    "\n",
    "    train_df.to_csv('train_labels.csv', index=False)\n",
    "    val_df.to_csv('val_labels.csv', index=False)\n",
    "\n",
    "    print(f\"Validation - Num malignant: {val_df[MALIGNANT].sum()}\")\n",
    "    print(f\"Validation - Num benign: {len(val_df) - val_df[MALIGNANT].sum()}\")\n",
    "    print(f\"Training - Num malignant: {train_df[MALIGNANT].sum()}\")\n",
    "    print(f\"Training - Num benign: {len(train_df) - train_df[MALIGNANT].sum()}\")\n",
    "\n",
    "    class ISICDataset(Dataset):\n",
    "        def __init__(self, csv_file, img_dir, non_malignant_transform=None, malignant_transform=None,label_col=MALIGNANT,aug_dir = None, train_bool = False):\n",
    "            self.fulldata = pd.read_csv(csv_file)\n",
    "            self.train = train_bool\n",
    "            if self.train:\n",
    "                self.malig_df = self.fulldata[self.fulldata[label_col] ==1]\n",
    "                self.non_malig_df = self.fulldata[self.fulldata[label_col] ==0]\n",
    "                self.min_count = min(len(self.malig_df), len(self.non_malig_df))\n",
    "                non_malig_df_balanced = self.non_malig_df.sample(n=self.min_count)\n",
    "\n",
    "                # Concatenate back\n",
    "                self.df = pd.concat([self.malig_df, non_malig_df_balanced]).sample(frac=1).reset_index(drop=True)\n",
    "                self.SOURCE_IDX = self.df.columns.get_loc(\"source\")\n",
    "            else:\n",
    "                self.df = self.fulldata\n",
    "            \n",
    "            self.img_dir = img_dir\n",
    "            self.aug_dir = aug_dir\n",
    "            self.non_malignant_transform = non_malignant_transform\n",
    "            self.malignant_transform = malignant_transform\n",
    "\n",
    "        def rebalance(self):\n",
    "            if not self.train:\n",
    "                return\n",
    "\n",
    "            non_malig_df_balanced = self.non_malig_df.sample(n=self.min_count)\n",
    "            # Concatenate back\n",
    "            self.df = pd.concat([self.malig_df, non_malig_df_balanced]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.df)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            if(self.aug_dir == None):\n",
    "                img_path = os.path.join(self.img_dir, self.df.iloc[idx, 0] + '.jpg')\n",
    "\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "                if self.df.iloc[idx, MALIG_IDX] == 0 and self.non_malignant_transform:\n",
    "                    image = self.non_malignant_transform(image)\n",
    "                elif self.df.iloc[idx, MALIG_IDX] == 1 and self.malignant_transform:\n",
    "                    image = self.malignant_transform(image)\n",
    "\n",
    "                return image, int(self.df.iloc[idx, MALIG_IDX]), self.df.iloc[idx, 0]\n",
    "            else:\n",
    "                if(self.df.iloc[idx, self.SOURCE_IDX] == 0):\n",
    "\n",
    "                    img_path = os.path.join(self.img_dir, self.df.iloc[idx, 0] + '.jpg')\n",
    "\n",
    "                    image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "                    if self.df.iloc[idx, MALIG_IDX] == 0 and self.non_malignant_transform:\n",
    "                        image = self.non_malignant_transform(image)\n",
    "                    elif self.df.iloc[idx, MALIG_IDX] == 1 and self.malignant_transform:\n",
    "                        image = self.malignant_transform(image)\n",
    "\n",
    "                    return image, int(self.df.iloc[idx, MALIG_IDX]), self.df.iloc[idx, 0] \n",
    "                else:\n",
    "                    #print(self.df.iloc[idx, 0])\n",
    "                    img_path = os.path.join(self.aug_dir, self.df.iloc[idx, 0] + '.jpg')\n",
    "\n",
    "                    image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "                    if self.df.iloc[idx, MALIG_IDX] == 0 and self.non_malignant_transform:\n",
    "                        image = self.non_malignant_transform(image)\n",
    "                    elif self.df.iloc[idx, MALIG_IDX] == 1 and self.malignant_transform:\n",
    "                        image = self.malignant_transform(image)\n",
    "\n",
    "                    return image, int(self.df.iloc[idx, MALIG_IDX]), self.df.iloc[idx, 0] \n",
    "\n",
    "\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet means\n",
    "                            std=[0.229, 0.224, 0.225])    # ImageNet stds\n",
    "    ])\n",
    "\n",
    "    malignant_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_dataset = ISICDataset(\n",
    "        csv_file='val_labels.csv',\n",
    "        img_dir=TEST_DIR[dir],\n",
    "        non_malignant_transform=transform,\n",
    "        malignant_transform=transform\n",
    "    )\n",
    "\n",
    "    train_dataset = ISICDataset(\n",
    "        csv_file='train_labels.csv',\n",
    "        img_dir=TRAIN_DIR[dir],\n",
    "        non_malignant_transform=malignant_transform,\n",
    "        malignant_transform=malignant_transform,\n",
    "        aug_dir = AUG_DIR, \n",
    "        train_bool = True\n",
    "    )\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training on {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
    "\n",
    "    for model_name in MODELS:\n",
    "        resnet = initialize_model(model_name=model_name, num_classes=1)\n",
    "\n",
    "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=1e-4)\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([2.0]).to(device))\n",
    "\n",
    "        # switch to this if we're doing more than malignant/not-malignant\n",
    "        #criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        resnet.to(device)\n",
    "\n",
    "        with open(f\"training_log_{model_name}_{DATA_NAMES[dir]}.csv\", \"w\") as f:\n",
    "            f.write(\"epoch,train_loss,val_loss,val_tn,val_fn,val_tp,val_fp,val_accuracy,val_auc,pauc,f1score\\n\")\n",
    "            start_time = time.time()\n",
    "            for epoch in range(EPOCHS):\n",
    "                train_dataset.rebalance()\n",
    "                dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "                valloader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "                print(f\"Training set size: {len(dataloader.dataset)}\")\n",
    "                print(f\"Validation set size: {len(valloader.dataset)}\")\n",
    "\n",
    "                resnet.train()\n",
    "                avgloss = 0.0\n",
    "                print(f\"EPOCH: {epoch + 1}\")\n",
    "                for images, labels, _ in dataloader:\n",
    "                    images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = resnet(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    avgloss += loss.item() * images.size(0)\n",
    "                avgloss /= len(dataloader.dataset)\n",
    "\n",
    "                resnet.eval()\n",
    "                val_loss = 0.0\n",
    "                total = 0\n",
    "                false_negative = 0\n",
    "                false_positive = 0\n",
    "                true_negative = 0\n",
    "                true_positive = 0\n",
    "                all_labels = []\n",
    "                all_probs = []  # Store probabilities instead of binary predictions\n",
    "                image_ids_list = []  # Collect image IDs for submission\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for images, labels, image_ids in valloader:  # Ensure dataset returns image IDs\n",
    "                        images = images.to(device)\n",
    "                        labels = labels.to(device).float().unsqueeze(1)\n",
    "                        \n",
    "                        # Forward pass\n",
    "                        outputs = resnet(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        val_loss += loss.item() * images.size(0)\n",
    "\n",
    "                        # Get probabilities (before thresholding)\n",
    "                        probabilities = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
    "                        all_probs.extend(probabilities)\n",
    "                        \n",
    "                        # Get binary predictions for confusion matrix\n",
    "                        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "                        preds = preds.cpu().numpy().flatten()\n",
    "                        \n",
    "                        # Track image IDs for submission\n",
    "                        image_ids_list.extend(image_ids)  # Assuming image_ids are strings\n",
    "                        \n",
    "                        # Update confusion matrix\n",
    "                        for p, l in zip(preds, labels.cpu().numpy()):\n",
    "                            if p == 0 and l == 0:\n",
    "                                true_negative += 1\n",
    "                            elif p == 0 and l == 1:\n",
    "                                false_negative += 1\n",
    "                            elif p == 1 and l == 0:\n",
    "                                false_positive += 1\n",
    "                            elif p == 1 and l == 1:\n",
    "                                true_positive += 1\n",
    "                        total += labels.size(0)\n",
    "                        all_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "                # Calculate metrics\n",
    "                avg_val_loss = val_loss / len(valloader.dataset)\n",
    "                accuracy = (true_positive + true_negative) / total\n",
    "                p_auc = roc_auc_score(all_labels, all_probs)  # Use probabilities for AUC\n",
    "                f1score = f1_score(all_labels, [1 if x > 0.5 else 0 for x in all_probs])\n",
    "\n",
    "                # Create submission DataFrame\n",
    "                submission_df = pd.DataFrame({\n",
    "                    'isic_id': image_ids_list,\n",
    "                    'prediction': all_probs\n",
    "                })\n",
    "\n",
    "                solution_df = pd.DataFrame({\n",
    "                    'isic_id': image_ids_list,\n",
    "                    'is_malignant': all_labels\n",
    "                })\n",
    "\n",
    "                # Calculate pAUC using the competition metric\n",
    "                try:\n",
    "                    pAUC = score(\n",
    "                        solution=solution_df,\n",
    "                        submission=submission_df,\n",
    "                        row_id_column_name='isic_id'  # Must match your column name\n",
    "                    )\n",
    "                except ParticipantVisibleError as e:\n",
    "                    print(f\"Scoring Error: {e}\")\n",
    "                    pAUC = -1  # Handle invalid submissions\n",
    "\n",
    "                if (epoch+1) % 5 == 0:\n",
    "                    torch.save(resnet.state_dict(), f\"resnet50_{epoch}_{DUPE}_{FREEZE}_pos_weight(2).pth\")\n",
    "                \n",
    "                print(f\"Epoch [{epoch+1}/{EPOCHS}] \"\n",
    "                    f\"Train Loss: {avgloss:.4f} \"\n",
    "                    f\"Val Loss: {avg_val_loss:.4f}\\n\"\n",
    "                    f\"Val TN: {true_negative} FN: {false_negative} \\n\"\n",
    "                    f\"TP: {true_positive} FP: {false_positive}\\n\"\n",
    "                    f\"Val Accuracy: {accuracy:.4f}\\n\"\n",
    "                    f\"AUC: {p_auc:.4f}\\n\"\n",
    "                    f\"pAUC: {pAUC:.4f}\\n\"\n",
    "                    f\"f1 score: {f1score:.4f}\\n\")  # Add pAUC to output'\n",
    "                f.write(f\"{epoch+1},{avgloss},{avg_val_loss},{true_negative},{false_negative},{true_positive},{false_positive},{accuracy},{p_auc},{pAUC},{f1score}\\n\")\n",
    "            \n",
    "            \n",
    "        print(f\"Training time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "        with open(f\"scores_{model_name}_{DATA_NAMES[dir]}.csv\", \"w\") as f:\n",
    "            f.write(\"isic_id,prediction,target\\n\")\n",
    "            for id, fscore, actual in zip(image_ids_list, all_probs, all_labels):\n",
    "                f.write(f\"{id},{fscore},{actual}\\n\")\n",
    "\n",
    "        \n",
    "\n",
    "        def plot_roc_and_pauc(y_true, y_scores, min_tpr=0.80):\n",
    "            # Flip labels and predictions (based on your scoring function)\n",
    "            v_gt = abs(np.asarray(y_true) - 1)\n",
    "            v_pred = -1.0 * np.asarray(y_scores)\n",
    "\n",
    "            # Calculate ROC curve\n",
    "            fpr, tpr, thresholds = roc_curve(v_gt, v_pred)\n",
    "\n",
    "            # Compute full AUC and partial AUC\n",
    "            full_auc = auc(fpr, tpr)\n",
    "            max_fpr = abs(1 - min_tpr)\n",
    "\n",
    "            # Partial AUC calculation (manual interpolation for the cutoff point)\n",
    "            stop = np.searchsorted(fpr, max_fpr, \"right\")\n",
    "            x_interp = [fpr[stop - 1], fpr[stop]]\n",
    "            y_interp = [tpr[stop - 1], tpr[stop]]\n",
    "            \n",
    "            # Interpolated TPR at max_fpr\n",
    "            interp_tpr = np.interp(max_fpr, x_interp, y_interp)\n",
    "            \n",
    "            # Create partial ROC arrays up to max_fpr\n",
    "            pauc_fpr = np.append(fpr[:stop], max_fpr)\n",
    "            pauc_tpr = np.append(tpr[:stop], interp_tpr)\n",
    "            \n",
    "            partial_auc = auc(pauc_fpr, pauc_tpr)\n",
    "\n",
    "            # Plotting\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {full_auc:.4f})\")\n",
    "            \n",
    "            # Shade pAUC region\n",
    "            plt.fill_between(pauc_fpr, pauc_tpr, step=\"post\", alpha=0.3, color=\"orange\", label=f\"pAUC = {partial_auc:.4f}\")\n",
    "            \n",
    "            # Draw horizontal line at TPR = min_tpr\n",
    "            plt.axhline(min_tpr, color='red', linestyle='--', label=f\"Min TPR = {min_tpr}\")\n",
    "\n",
    "            # Draw vertical line at FPR = max_fpr\n",
    "            plt.axvline(max_fpr, color='green', linestyle='--', label=f\"Max FPR = {max_fpr:.2f}\")\n",
    "\n",
    "            plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "            plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "            plt.title(\"ROC Curve with pAUC Region Highlighted\")\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.grid(True)\n",
    "            plt.savefig(f\"roc_curve_{model_name}_{DATA_NAMES[dir]}.png\")\n",
    "\n",
    "        # Example usage\n",
    "        plot_roc_and_pauc(all_labels, all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting timm\n",
      "  Downloading timm-1.0.15-py3-none-any.whl.metadata (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/forestz/.local/lib/python3.11/site-packages (from timm) (2.6.0)\n",
      "Requirement already satisfied: torchvision in /home/forestz/.local/lib/python3.11/site-packages (from timm) (0.21.0)\n",
      "Requirement already satisfied: pyyaml in /sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages (from timm) (6.0.1)\n",
      "Collecting huggingface_hub (from timm)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors (from timm)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages (from huggingface_hub->timm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages (from huggingface_hub->timm) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages (from huggingface_hub->timm) (23.1)\n",
      "Requirement already satisfied: requests in /sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages (from huggingface_hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages (from huggingface_hub->timm) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/forestz/.local/lib/python3.11/site-packages (from huggingface_hub->timm) (4.12.2)\n",
      "Requirement already satisfied: networkx in /sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages (from torch->timm) (3.1)\n",
      "Requirement already satisfied: jinja2 in /sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages (from torch->timm) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/forestz/.local/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/forestz/.local/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/forestz/.local/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/forestz/.local/lib/python3.11/site-packages (from torch->timm) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/forestz/.local/lib/python3.11/site-packages (from torch->timm) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/forestz/.local/lib/python3.11/site-packages (from torch->timm) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/forestz/.local/lib/python3.11/site-packages (from torch->timm) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/forestz/.local/lib/python3.11/site-packages (from torch->timm) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/forestz/.local/lib/python3.11/site-packages (from torch->timm) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/forestz/.local/lib/python3.11/site-packages (from torch->timm) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/forestz/.local/lib/python3.11/site-packages (from torch->timm) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/forestz/.local/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/forestz/.local/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/forestz/.local/lib/python3.11/site-packages (from torch->timm) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/forestz/.local/lib/python3.11/site-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: numpy in /sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages (from torchvision->timm) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages (from jinja2->torch->timm) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sw/pkgs/arc/python3.11-anaconda/2024.02-1/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
      "Downloading timm-1.0.15-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.4/481.4 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, huggingface_hub, timm\n",
      "Successfully installed huggingface_hub-0.30.2 safetensors-0.5.3 timm-1.0.15\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48693\n"
     ]
    }
   ],
   "source": [
    "n = train_df[train_df.iloc[:, 0].isna()]\n",
    "\n",
    "print(len(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
